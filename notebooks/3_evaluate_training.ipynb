{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained U-Net\n",
    "After training, this notebook can be used to evaluate the training efficacy. It generates a plot of segmentation metrics, and predicts on images in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate segmentation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loaded checkpoint: ../src/models/dl4mia_tissue_unet/results\\20230424_164159/best.pth\n",
      "\tepoch = 199\n",
      "\tval_loss = 0.028927008310953777\n",
      "\tval_ap = 1.0589067141215007\n",
      "\tval_dice = 0.9728603760401408\n",
      "\tbest_loss = 0.0\n",
      "\tbest_dice = 1.0050761500994365\n",
      "\ttrain_cuda = True\n",
      "\tmodel_dict = {'name': 'unet', 'kwargs': {'num_classes': 1, 'depth': 3, 'in_channels': 1, 'batch_norm': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 2/39 [00:00<00:02, 17.10it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Ground truth image for binary metric must be binary. Invalid values: [0 1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m data_dir \u001b[39m=\u001b[39m (\n\u001b[0;32m     14\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mC:/VirEnvs/OCT_segmentation/unet_segmentation/data/processed/OCT_scans_new_20230419_skull_128x128\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m   )\n\u001b[0;32m     16\u001b[0m compare \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m evaluate\u001b[39m.\u001b[39;49mmain(src_dir\u001b[39m=\u001b[39;49mresult_dir, data_dir \u001b[39m=\u001b[39;49m data_dir, compare\u001b[39m=\u001b[39;49mcompare)\n",
      "File \u001b[1;32mc:\\virenvs\\oct_segmentation\\unet_segmentation\\src\\models\\dl4mia_tissue_unet\\evaluate.py:236\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(src_dir, data_dir, ckpt_name, compare, max_compare)\u001b[0m\n\u001b[0;32m    233\u001b[0m mdl \u001b[39m=\u001b[39m load_model(ckpt_path)\n\u001b[0;32m    235\u001b[0m \u001b[39m# Compile the segmentation metrics for test and validation paths and save csv and plot\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m seg_metrics_df \u001b[39m=\u001b[39m compile_binary_seg_results(\n\u001b[0;32m    237\u001b[0m     segmenter\u001b[39m=\u001b[39;49mmdl, img_paths\u001b[39m=\u001b[39;49mtv_img_paths, mask_paths\u001b[39m=\u001b[39;49mtv_mask_paths\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    239\u001b[0m save_seg_results(seg_df\u001b[39m=\u001b[39mseg_metrics_df, output_dir\u001b[39m=\u001b[39meval_out_dir)\n\u001b[0;32m    240\u001b[0m plot_seg_boxplot(seg_metrics_df, save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\virenvs\\oct_segmentation\\unet_segmentation\\src\\models\\dl4mia_tissue_unet\\evaluate.py:95\u001b[0m, in \u001b[0;36mcompile_binary_seg_results\u001b[1;34m(segmenter, img_paths, mask_paths)\u001b[0m\n\u001b[0;32m     92\u001b[0m seg, _ \u001b[39m=\u001b[39m segmenter\u001b[39m.\u001b[39mpredict(img)\n\u001b[0;32m     94\u001b[0m \u001b[39m# Compute segmentation metrics\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m acc, dice, prec, spec, rec \u001b[39m=\u001b[39m binary_sem_seg_metrics(\n\u001b[0;32m     96\u001b[0m     y_true\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m     97\u001b[0m     y_pred\u001b[39m=\u001b[39;49mseg,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39m# Add to dataframe\u001b[39;00m\n\u001b[0;32m    101\u001b[0m tmp_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m: [img_path],\n\u001b[0;32m    103\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgt\u001b[39m\u001b[39m\"\u001b[39m: [mask_path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrec\u001b[39m\u001b[39m\"\u001b[39m: [rec],\n\u001b[0;32m    109\u001b[0m }\n",
      "File \u001b[1;32mc:\\virenvs\\oct_segmentation\\unet_segmentation\\src\\models\\dl4mia_tissue_unet\\dl4mia_utils\\metrics.py:247\u001b[0m, in \u001b[0;36mbinary_sem_seg_metrics\u001b[1;34m(y_true, y_pred, eps)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Takes a binary ground truth ndarray and the associated binary\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mprediction ndarray and returns the segmentation metrics: accuracy, dice\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m(same as f1 for binary semantic segmentation), precision, specificity and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39m    accuracy, dice, precision, specificity and recall of prediction\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39massert\u001b[39;00m y_true\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m y_pred\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39mImages for metrics must be same shape\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 247\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m    248\u001b[0m     \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    249\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGround truth image for binary metric must be binary. Invalid values: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_true)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m    251\u001b[0m     \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_pred)) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    252\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrediction image for binary metric must be binary. Invalid values: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_pred)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     np\u001b[39m.\u001b[39mamin(y_true) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mamax(y_true) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    255\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGround truth image for binary metric must be 0-1 valued. Invalid values: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_true)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Ground truth image for binary metric must be binary. Invalid values: [0 1 2]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.models.dl4mia_tissue_unet import evaluate\n",
    "import glob\n",
    "\n",
    "# Find the training session folders in the output directory\n",
    "output_dir = \"../src/models/dl4mia_tissue_unet/results\"\n",
    "res_dirs = glob.glob(f\"{output_dir}/*\")\n",
    "\n",
    "# Load the \"best\" checkpoint from the most recent training session and predict\n",
    "if res_dirs != []:\n",
    "  result_dir = res_dirs[-1]\n",
    "  data_dir = (\n",
    "        \"C:/VirEnvs/OCT_segmentation/unet_segmentation/data/processed/OCT_scans_new_20230419_skull_128x128\"\n",
    "    )\n",
    "  compare = True\n",
    "  evaluate.main(src_dir=result_dir, data_dir = data_dir, compare=compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCT_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
