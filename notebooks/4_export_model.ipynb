{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export PyTorch Model to ONNX\n",
    "\n",
    "Zahra needs `.onnx` files to be used in Labview, but PyTorch saves the model weights/checkpoints as `.pth` files. Hence, we need to conver the PyTorch `.pth` weights to `.onnx` weights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that converts model to `.onnx`. As arguments, it takes the trained model, a `torch.Tensor` of the the same size *(BATCH, CHANNEL, HEIGHT, WIDTH)* as is expected by the model (the values in the tensor aren't important), and the filepath of where to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "def my_export_onnx(model:torch.nn.Module, im:torch.Tensor, filepath:str, cpu:bool = True):\n",
    "    \"\"\"\n",
    "    Export model to `.onnx` file. \n",
    "    \n",
    "    Args:\n",
    "        model: Model to convert to .onnx file\n",
    "        im (torch.Tensor): Input tensor of expected size for inference\n",
    "        filepath (str): Location to save file\n",
    "        cpu (bool): True to send to cpu before export\n",
    "    \"\"\"\n",
    "    save_dir = Path(filepath).parent.absolute()\n",
    "    if not os.path.isdir(save_dir):\n",
    "        raise ValueError(f\"Invalid path to save: {filepath}. Parent directory doesn't exist\")\n",
    "    exten = Path(filepath).suffix\n",
    "    if exten != \".onnx\":\n",
    "        raise ValueError(f\"Invalid path to save: {filepath}. Must be `.onnx` file.\")\n",
    "    _shape = im.shape\n",
    "    if len(_shape) != 4:\n",
    "        raise ValueError(f\"Invalid input tensor shape {_shape}. Must be (?, 1, ?, ?) -> (B, C, H, W).\")\n",
    "    if _shape[1] != 1:\n",
    "        raise ValueError(f\"Invalid input tensor shape {_shape}. Must have 1 channel -> (B, C, H, W).\")\n",
    "    \n",
    "\n",
    "    print(f\"Starting `.onnx.` export to: {filepath}\")\n",
    "    \n",
    "    # set the model to inference mode \n",
    "    model.eval()\n",
    "\n",
    "    if not cpu:\n",
    "        raise NotImplementedError(\"Must use cpu\")\n",
    "    else:\n",
    "        model = model.cpu()\n",
    "        im = im.cpu()\n",
    "\n",
    "    # Export model to .onnx file\n",
    "    torch.onnx.export(\n",
    "        model,                          # Model to save\n",
    "        im,                             # Dummy torch.Tensor of expected size\n",
    "        filepath,                       # Filepath to save\n",
    "        export_params = True,           # store the trained parameter weights inside the model file \n",
    "        opset_version = 12,             # the ONNX version to export the model to\n",
    "        do_constant_folding = True,     # whether to execute constant folding for optimization\n",
    "        input_names = ['images'],       # the model's input names\n",
    "        output_names = ['outputs'],     # the model's output names\n",
    "        dynamic_axes = {                # Axes of inputs outputs that can change at runtime (aka diff batch size than im )\n",
    "            \"images\": {0: \"batch_size\"},\n",
    "            \"outputs\": {0: \"batch_size\"},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Checks\n",
    "    model_onnx = onnx.load(filepath)  # load onnx model\n",
    "    onnx.checker.check_model(model_onnx)  # check onnx model\n",
    "\n",
    "    print(\"ONNX file successfully created!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With function defined, now we can load the model from the `.pth` file and save it to `.onnx` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder name and filenames for where to load/save the model\n",
    "models_dir = \"../src/models/dl4mia_tissue_unet/results\"\n",
    "dir_name = \"20230508_104630\"\n",
    "src_name = \"best.pth\"\n",
    "dst_name = f\"{dir_name}_{os.path.splitext(src_name)[0]}.onnx\"\n",
    "\n",
    "# Specify filepaths\n",
    "src_file = f\"{models_dir}/{dir_name}/{src_name}\"\n",
    "dst_file = f\"{models_dir}/{dir_name}/{dst_name}\"\n",
    "\n",
    "assert os.path.exists(src_file), \"Source `.pth` file not a valid path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading `.pth` file: ../src/models/dl4mia_tissue_unet/results/20230508_104630/best.pth\n",
      "Trained model info:\n",
      "\tepoch = 98\n",
      "\tval_loss = 0.14062084142978376\n",
      "\tval_ap = 0.9189547437887925\n",
      "\tval_dice = 0.859847577718588\n",
      "\tbest_loss = 0\n",
      "\tbest_dice = 0.9133516412514907\n",
      "\ttrain_cuda = True\n",
      "\tmodel_dict = {'name': 'unet', 'kwargs': {'num_classes': 1, 'depth': 3, 'in_channels': 1, 'batch_norm': True}}\n",
      "`.pth` file successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load the model to save to .onnx\n",
    "from src.models.dl4mia_tissue_unet import (model as v1, model_v2 as v2)\n",
    "device = \"cpu\"\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Open .pth file and send to model\n",
    "print(f\"Loading `.pth` file: {src_file}\")\n",
    "checkpoint = torch.load(src_file, map_location=device)\n",
    "state_dict = checkpoint[\"model_state_dict\"]\n",
    "model_dict = checkpoint[\"model_dict\"]\n",
    "print(\"Trained model info:\")\n",
    "for key in checkpoint:\n",
    "    if \"state_dict\" not in key and \"logger_data\" not in key:\n",
    "        print(f\"\\t{key} = {checkpoint[key]}\")\n",
    "model = v2.UNet(**model_dict[\"kwargs\"])\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.to(device)\n",
    "print(\"`.pth` file successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model input of size torch.Size([1, 1, 512, 512]) (B, C, H, W)\n"
     ]
    }
   ],
   "source": [
    "# Create \"dummy\" input tensor of expected size/shape for the model\n",
    "batch = 1\n",
    "channel = 1\n",
    "height = 512\n",
    "width = 512\n",
    "im = torch.zeros(batch, channel, height, width)\n",
    "print(f\"Created model input of size {im.shape} (B, C, H, W)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "out = model(im)\n",
    "print(im.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting `.onnx.` export to: ../src/models/dl4mia_tissue_unet/results/20230508_104630/20230508_104630_best.onnx\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "ONNX file successfully created!\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "my_export_onnx(model=model, im=im, filepath=dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCT_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
